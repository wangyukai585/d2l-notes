作为机器学习科学家，我们的目标是发现_模式_（pattern）。

将模型在训练数据上拟合的比在潜在分布中更接近的现象称为_过拟合_（overfitting）， 用于对抗过拟合的技术称为_正则化_（regularization）。

## 4.4.1 训练误差和泛化误差

_训练误差_（training error）是指， 模型在训练数据集上计算得到的误差。 _泛化误差_（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

### 统计学习理论

 我们假设训练数据和测试数据都是从相同的分布中独立提取的。 这通常被称为_独立同分布假设_（i.i.d. assumption）

我们将讨论因违背独立同分布假设而引起的问题

### 模型复杂性

通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂， 而需要_早停_（early stopping）的模型（即较少训练迭代周期）就不那么复杂。

我们将重点介绍几个倾向于影响模型泛化的因素。

1. 可调整参数的数量。当可调整参数的数量（有时称为_自由度_）很大时，模型往往更容易过拟合。
2. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。
3. 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。

## 4.4.2 模型选择

在机器学习中，我们通常在评估几个候选模型后选择最终的模型。 这个过程叫做_模型选择_。

为了确定候选模型中的最佳模型，我们通常会使用验证集。

### 验证集

将我们的数据分成三份， 除了训练和测试数据集之外，还增加一个_验证数据集_（validation dataset）， 也叫_验证集_（validation set）。

在这本书的实验中， 我们实际上是在使用应该被正确地称为训练数据和验证数据的数据集， 并没有真正的测试数据集。 因此，书中每次实验报告的准确度都是验证集准确度，而不是测试集准确度。

### K折交叉验证

当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。 这个问题的一个流行的解决方案是采用K_折交叉验证_。 这里，原始训练数据被分成K个不重叠的子集。 然后执行K次模型训练和验证，每次在K-1个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。 最后，通过对K次实验的结果取平均来估计训练和验证误差。

## 4.4.3 欠拟合还是过拟合？

由于我们的训练和验证误差之间的_泛化误差_很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为_欠拟合_（underfitting）。

当我们的训练误差明显低于验证误差时要小心， 这表明严重的_过拟合_（overfitting）。

### 模型复杂性

![[Pasted image 20251029204523.png]]
图4.4.1 模型复杂度对欠拟合和过拟合的影响

### 数据集大小

 随着训练数据量的增加，泛化误差通常会减小。
对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型

## 4.4.4 多项式回归

### 生成数据集

### 对模型进行训练和测试

```python
def evaluate_loss(net, data_iter, loss):  #@save
    """评估给定数据集上模型的损失"""
    metric = d2l.Accumulator(2)  # 损失的总和,样本数量
    for X, y in data_iter:
        out = net(X)
        y = y.reshape(out.shape)
        l = loss(out, y)
        metric.add(l.sum(), l.numel())
    return metric[0] / metric[1]
```

训练函数
```python
def train(train_features, test_features, train_labels, test_labels,
          num_epochs=400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    # 不设置偏置，因为我们已经在多项式中实现了它
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))
    batch_size = min(10, train_labels.shape[0])
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),
                                batch_size)
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),
                               batch_size, is_train=False)
    trainer = torch.optim.SGD(net.parameters(), lr=0.01)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',
                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],
                            legend=['train', 'test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),
                                     evaluate_loss(net, test_iter, loss)))
    print('weight:', net[0].weight.data.numpy())
```

这个过于复杂的模型会轻易受到训练数据中噪声的影响。 虽然训练损失可以有效地降低，但测试损失仍然很高。 结果表明，复杂模型对数据造成了过拟合。

## 4.4.5 小结

- 欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。
- 由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要注意防止过拟合，即防止泛化误差过大。
- 验证集可以用于模型选择，但不能过于随意地使用它。
- 我们应该选择一个复杂度适当的模型，避免使用数量不足的训练样本。


