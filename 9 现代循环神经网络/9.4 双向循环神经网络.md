不同长度的上下文范围重要性是相同的。

## 隐马尔可夫模型中的动态规划

可以设计一个隐变量模型： 在任意时间步𝑡，假设存在某个隐变量ℎ𝑡， 通过概率𝑃(𝑥𝑡∣ℎ𝑡)控制我们观测到的𝑥𝑡。 此外，任何ℎ𝑡→ℎ𝑡+1转移 都是由一些状态转移概率𝑃(ℎ𝑡+1∣ℎ𝑡)给出。 这个概率图模型就是一个_隐马尔可夫模型_（hidden Markov model，HMM）
![[Pasted image 20251110224416.png]]

因此，对于有$T$个观测值的序列，
我们在观测状态和隐状态上具有以下联合概率分布：

$$P(x_1, \ldots, x_T, h_1, \ldots, h_T) = \prod_{t=1}^T P(h_t \mid h_{t-1}) P(x_t \mid h_t), \text{ where } P(h_1 \mid h_0) = P(h_1).$$

## 双向模型

![[Pasted image 20251110225417.png]]
_双向循环神经网络_（bidirectional RNNs） 添加了反向传递信息的隐藏层，以便更灵活地处理此类信息。

### 定义

![[PixPin_2025-11-10_22-55-38 1.png]]

### 模型的计算代价及其应用

 具体地说，在训练期间，我们能够利用过去和未来的数据来估计现在空缺的词； 而在测试期间，我们只有过去的数据。
双向循环神经网络的计算速度非常慢

双向层的使用在实践中非常少，并且仅仅应用于部分场合。 例如，填充缺失的单词、词元注释（例如，用于命名实体识别） 以及作为序列处理流水线中的一个步骤对序列进行编码（例如，用于机器翻译）。

## 小结

- 在双向循环神经网络中，每个时间步的隐状态由当前时间步的前后数据同时决定。
- 双向循环神经网络与概率图模型中的“前向-后向”算法具有相似性。
- 双向循环神经网络主要用于序列编码和给定双向上下文的观测估计。
- 由于梯度链更长，因此双向循环神经网络的训练代价非常高。