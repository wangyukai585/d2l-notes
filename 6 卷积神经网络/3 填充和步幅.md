比如，一个240×240像素的图像，经过10层5×5的卷积后，将减少到200×200像素。如此一来，原始图像的边界丢失了许多有用信息。而_填充_是解决此问题最有效的方法； 有时，我们可能希望大幅降低图像的宽度和高度。例如，如果我们发现原始的输入分辨率十分冗余。_步幅_则可以在这类情况下提供帮助。

## 填充

![[Pasted image 20251118234542.png]]

通常，如果我们添加$p_h$行填充（大约一半在顶部，一半在底部）和$p_w$列填充（左侧大约一半，右侧一半），则输出形状将为

$$(n_h-k_h+p_h+1)\times(n_w-k_w+p_w+1)。$$

这意味着输出的高度和宽度将分别增加$p_h$和$p_w$。

假设$k_h$是奇数，我们将在高度的两侧填充$p_h/2$行。
如果$k_h$是偶数，则一种可能性是在输入顶部填充$\lceil p_h/2\rceil$行，在底部填充$\lfloor p_h/2\rfloor$行。同理，我们填充宽度的两侧。

卷积神经网络中卷积核的高度和宽度通常为奇数，例如1、3、5或7。
选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。

在下面的例子中，我们创建一个高度和宽度为3的二维卷积层，并(**在所有侧边填充1个像素**)。给定高度和宽度为8的输入，则输出的高度和宽度也是8。

 **通道 = 特征图（feature maps）**
卷积核越多 → 提取的特征越丰富

## 步幅

我们将每次滑动元素的数量称为_步幅_（stride）。

![[Pasted image 20251119001619.png]]

垂直步幅为3，水平步幅为2的二维互相关运算

当输入高度和宽度两侧的填充数量分别为𝑝ℎ和𝑝𝑤时，我们称之为填充(𝑝ℎ,𝑝𝑤)。当𝑝ℎ=𝑝𝑤=𝑝时，填充是𝑝。

当高度和宽度上的步幅分别为𝑠ℎ和𝑠𝑤时，我们称之为步幅(𝑠ℎ,𝑠𝑤)。特别地，当𝑠ℎ=𝑠𝑤=𝑠时，我们称步幅为𝑠。

默认情况下，填充为0，步幅为1。在实践中，我们很少使用不一致的步幅或填充，也就是说，我们通常有𝑝ℎ=𝑝𝑤和𝑠ℎ=𝑠𝑤。

## 小结

- 充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。
- 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的1/𝑛（𝑛是一个大于1的整数）。
- 填充和步幅可用于有效地调整数据的维度。


