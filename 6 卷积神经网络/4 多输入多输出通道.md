当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有3×ℎ×𝑤的形状。我们将这个大小为3的轴称为_通道_（channel）维度

## 多输入通道

当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。

![[Pasted image 20251119002957.png]]

```python
def corr2d_multi_in(X, K):
    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起
    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))
```

## 多输出通道

我们可以将每个通道看作对不同特征的响应。

用𝑐𝑖和𝑐𝑜分别表示输入和输出通道的数目，并让𝑘ℎ和𝑘𝑤为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为𝑐𝑖×𝑘ℎ×𝑘𝑤的卷积核张量，这样卷积核的形状是𝑐𝑜×𝑐𝑖×𝑘ℎ×𝑘𝑤。在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。

第一个通道的结果与先前输入张量`X`和多输入单输出通道的结果一致。

## 1×1卷积层

因为使用了最小窗口，1×1卷积失去了卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。 其实1×1卷积的唯一计算发生在通道上。

![[Pasted image 20251119005223.png]]

```python
def corr2d_multi_in_out_1x1(X, K):
    # X: 输入张量，形状 (c_i, h, w)
    # K: 卷积核，形状 (c_o, c_i, 1, 1)

    c_i, h, w = X.shape         # 输入通道数、高度、宽度
    c_o = K.shape[0]            # 输出通道数

    # 把输入变成 (c_i, h*w)
    # 意思：每个像素位置的 c_i 通道展成一列
    X = X.reshape((c_i, h * w))

    # 把卷积核 K 变成 (c_o, c_i)
    # 意思：每个输出通道都有一行权重，对输入通道做线性组合
    K = K.reshape((c_o, c_i))

    # 用矩阵乘法模拟 1×1 卷积
    # 对每一个像素位置都执行： output = K @ X
    # 输出形状是 (c_o, h*w)
    Y = torch.matmul(K, X)

    # 再 reshape 回卷积层输出的形状 (c_o, h, w)
    return Y.reshape((c_o, h, w))
```

所以 1×1 卷积本质上就是：

> **对每个像素位置执行一次全连接层（ci → co），并对所有位置共享权重。**

当执行1×1卷积运算时，上述函数相当于先前实现的互相关函数`corr2d_multi_in_out`。

## 小结

- 多输入多输出通道可以用来扩展卷积层的模型。
- 当以每像素为基础应用时，1×1卷积层相当于全连接层。
- 1×1卷积层通常用于调整网络层的通道数量和控制模型复杂性。
