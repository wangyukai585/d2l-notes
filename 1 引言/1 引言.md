
# 1.1 日常生活中的机器学习

- 参数可以被看作旋钮，旋钮的转动可以调整程序的行为。 
- 任一调整参数后的程序被称为_模型_（model）。
- 通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“模型族”。
- 使用数据集来选择参数的元程序被称为_学习算法_（learning algorithm）。

在机器学习中，_学习_（learning）是一个训练模型的过程。

训练过程通常包含如下步骤：

1. 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；
    
2. 获取一些数据样本（例如，音频片段以及对应的是或否标签）；
    
3. 调整参数，使模型在这些样本中表现得更好；
    
4. 重复第（2）步和第（3）步，直到模型在任务中的表现令人满意。
![[Pasted image 20251018002501.png]]

- “通过用数据集来确定程序行为”的方法可以被看作_用数据编程_（programming with data）


# 1.2 机器学习中的关键组件

1. 可以用来学习的_数据_（data）；
	    
2. 如何转换数据的_模型_（model）；
	    
3. 一个_目标函数_（objective function），用来量化模型的有效性；
    
4. 调整模型参数以优化目标函数的_算法_（algorithm）。


## 数据
每个数据集由一个个_样本_（example, sample）组成，大多时候，它们遵循独立同分布(independently and identically distributed, i.i.d.)。 样本有时也叫做_数据点_（data point）或者_数据实例_（data instance），通常每个样本由一组称为_特征_（features，或_协变量_（covariates））的属性组成。 机器学习模型会根据这些属性进行预测。 在上面的监督学习问题中，要预测的是一个特殊的属性，它被称为_标签_（label，或_目标_（target））。

当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的_维数_（dimensionality）。

## 模型

 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为_深度学习_（deep learning）。


## 目标函数

我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，这被称之为_目标函数_（objective function）。
 因为越低越好，所以这些函数有时被称为_损失函数_（loss function，或cost function）

当任务在试图预测数值时，最常见的损失函数是_平方误差_（squared error），即预测值与实际值之差的平方。
当试图解决分类问题时，最常见的目标函数是最小化错误率，即预测与实际情况不符的样本比例。

有些目标函数（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其他复杂性难以直接优化。 在这些情况下，通常会优化_替代目标_。

通常，损失函数是根据模型参数定义的，并取决于数据集。

该数据集由一些为训练而收集的样本组成，称为_训练数据集_（training dataset，或称为_训练集_（training set））。
“新数据集”通常称为_测试数据集_（test dataset，或称为_测试集_（test set））。

训练数据集用于拟合模型参数，测试数据集用于评估拟合的模型。

当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为_过拟合_（overfitting）的。

## 优化算法

深度学习中，大多流行的优化算法通常基于一种基本方法–_梯度下降_（gradient descent）。 简而言之，在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。


# 1.3 各种机器学习问题


## 监督学习

_监督学习_（supervised learning）擅长在“给定输入特征”的情况下预测标签。 每个“特征-标签”对都称为一个_样本_（example）。

监督学习的学习过程一般可以分为三大步骤：

1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签（例如，患者是否在下一年内康复？）；有时，这些样本可能需要被人工标记（例如，图像分类）。这些输入和相应的标签一起构成了训练数据集；
    
2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
    
3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测
![[Pasted image 20251018201434.png]]

### 回归

当标签取任意数值时，我们称之为_回归_问题

### 分类

这种“哪一个”的问题叫做_分类_（classification）问题。 _分类_问题希望模型能够预测样本属于哪个_类别_（category，正式称为_类_（class））。

 最简单的分类问题是只有两类，这被称之为_二项分类_（binomial classification）。

回归是训练一个回归函数来输出一个数值； 分类是训练一个分类器来输出预测的类别。

预测类别的概率的大小传达了一种模型的不确定性。

当有两个以上的类别时，我们把这个问题称为_多项分类_（multiclass classification）问题。

分类问题的常见损失函数被称为_交叉熵_（cross-entropy）

人们宁愿错误地分入一个相关的类别，也不愿错误地分入一个遥远的类别，这通常被称为_层次分类_(hierarchical classification)。

层次结构相关性可能取决于模型的使用者计划如何使用模型。

### 标记问题

学习预测不相互排斥的类别的问题称为_多标签分类_（multi-label classification）。

### 搜索

有时，我们不仅仅希望输出一个类别或一个实值。 在信息检索领域，我们希望对一组项目进行排序。

为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。

### 推荐系统

### 序列学习

**标记和解析**。这涉及到用属性注释文本序列。

**自动语音识别**

**文本到语音**

**机器翻译**

## 无监督学习

这类数据中不含有“目标”的机器学习问题通常被为_无监督学习_（unsupervised learning）

_聚类_（clustering）问题
_主成分分析_（principal component analysis）问题
_因果关系_（causality）和_概率图模型_（probabilistic graphical models）问题
_生成对抗性网络_（generative adversarial networks）


## 与环境互动

 这里所有学习都是在算法与环境断开后进行的，被称为_离线学习_（offline learning）。
 
 对于监督学习，从环境中收集数据的过程类似于 [图1.3.6](https://zh.d2l.ai/chapter_introduction/index.html#fig-data-collection)。
 ![[Pasted image 20251018205906.png]]

孤立地进行模式识别

这时我们可能会期望人工智能不仅能够做出预测，而且能够与真实环境互动。

当训练和测试数据不同时，最后一个问题提出了_分布偏移_（distribution shift）的问题

## 强化学习

如果你对使用机器学习开发与环境交互并采取行动感兴趣，那么最终可能会专注于_强化学习_（reinforcement learning）。

_深度强化学习_（deep reinforcement learning）将深度学习应用于强化学习的问题，是非常热门的研究领域。

在每个特定时间点，智能体从环境接收一些_观察_（observation），并且必须选择一个_动作_（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得_奖励_（reward）。 此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。
![[Pasted image 20251018210201.png]]

强化学习的目标是产生一个好的_策略_（policy）。 强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。

我们可以将任何监督学习问题转化为强化学习问题。 假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。 然后，我们可以创建一个环境，该环境给予智能体的奖励。 这个奖励与原始监督学习问题的损失函数是一致的。

强化学习者必须处理_学分分配_（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的。

必须处理部分可观测性问题。

当环境可被完全观察到时，强化学习问题被称为_马尔可夫决策过程_（markov decision process）。 当状态不依赖于之前的操作时，我们称该问题为_上下文赌博机_（contextual bandit problem）。 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的_多臂赌博机_（multi-armed bandit problem）。


# 1.4 起源

_神经网络_（neural networks）的得名源于生物灵感。其核心是当今大多数网络中都可以找到的几个关键原则：

- 线性和非线性处理单元的交替，通常称为_层_（layers）；
    
- 使用链式规则（也称为_反向传播_（backpropagation））一次性调整网络中的全部参数。

# 深度学习的发展

很明显，随机存取存储器没有跟上数据增长的步伐。 与此同时，算力的增长速度已经超过了现有数据的增长速度。

“系统研究人员构建更好的工具”和“统计建模人员构建更好的神经网络”之间的分工大大简化了工作。 例如，在2014年，对卡内基梅隆大学机器学习博士生来说，训练线性回归模型曾经是一个不容易的作业问题。 而现在，这项任务只需不到10行代码就能完成，这让每个程序员轻易掌握了它。


# 1.6 深度学习的成功案例


# 1.7 特点

深度学习是“深度”的，模型学习了许多“层”的转换，每一层提供一个层次的表示。 例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。 由于_表示学习_（representation learning）目的是寻找表示本身，因此深度学习可以称为“多级表示学习”。

 毋庸置疑，深度学习方法中最显著的共同点是使用端到端训练。

除了端到端的训练，人们正在经历从参数统计描述到完全非参数模型的转变。

与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试。

# 1.8 小结

- 机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。
    
- 表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。
    
- 深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。
    
- 最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（通过GPU）算力的突破来触发的。
    
- 整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。


# 1.9 练习

表示学习
端到端学习
超参数
梯度下降
启发式
可学习部分
自动化方法
特征工程
泛化能力
神经网络