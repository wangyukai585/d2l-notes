现在是时候学习如何加载和存储权重向量和整个模型了。

## 加载和保存张量

```python
import torch
from torch import nn
from torch.nn import functional as F

x = torch.arange(4)
torch.save(x, 'x-file')
```

```python
x2 = torch.load('x-file')
x2
```

```python
mydict = {'x': x, 'y': y}
torch.save(mydict, 'mydict')
mydict2 = torch.load('mydict')
mydict2
```

写入和读取从字符串映射到张量的字典

## 加载和保存模型参数

保存模型的参数而不是保存整个模型

```python
torch.save(net.state_dict(), 'mlp.params')
```

为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**] 这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)

```python
clone = MLP()
clone.load_state_dict(torch.load('mlp.params'))
clone.eval()
```

## 小结

- `save`和`load`函数可用于张量对象的文件读写。
- 我们可以通过参数字典保存和加载网络的全部参数。
- 保存架构必须在代码中完成，而不是在参数中完成。