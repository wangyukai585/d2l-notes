_è¯­è¨€æ¨¡å‹_ï¼ˆlanguage modelï¼‰çš„ç›®æ ‡æ˜¯ä¼°è®¡åºåˆ—çš„è”åˆæ¦‚ç‡
ğ‘ƒ(ğ‘¥1,ğ‘¥2,â€¦,ğ‘¥ğ‘‡).

## å­¦ä¹ è¯­è¨€æ¨¡å‹

å‡è®¾è®­ç»ƒæ•°æ®é›†æ˜¯ä¸€ä¸ªå¤§å‹çš„æ–‡æœ¬è¯­æ–™åº“ã€‚

è®­ç»ƒæ•°æ®é›†ä¸­è¯çš„æ¦‚ç‡å¯ä»¥æ ¹æ®ç»™å®šè¯çš„ç›¸å¯¹è¯é¢‘æ¥è®¡ç®—ã€‚ ä¾‹å¦‚ï¼Œå¯ä»¥å°†ä¼°è®¡å€¼ğ‘ƒÌ‚Â (deep)Â è®¡ç®—ä¸ºä»»ä½•ä»¥å•è¯â€œdeepâ€å¼€å¤´çš„å¥å­çš„æ¦‚ç‡ã€‚
ä¸€ç§ï¼ˆç¨ç¨ä¸å¤ªç²¾ç¡®çš„ï¼‰æ–¹æ³•æ˜¯ç»Ÿè®¡å•è¯â€œdeepâ€åœ¨æ•°æ®é›†ä¸­çš„å‡ºç°æ¬¡æ•°ï¼Œ ç„¶åå°†å…¶é™¤ä»¥æ•´ä¸ªè¯­æ–™åº“ä¸­çš„å•è¯æ€»æ•°ã€‚

æˆ‘ä»¬å¯ä»¥å°è¯•ä¼°è®¡

$$\hat{P}(\text{learning} \mid \text{deep}) = \frac{n(\text{deep, learning})}{n(\text{deep})},$$

å…¶ä¸­$n(x)$å’Œ$n(x, x')$åˆ†åˆ«æ˜¯å•ä¸ªå•è¯å’Œè¿ç»­å•è¯å¯¹çš„å‡ºç°æ¬¡æ•°ã€‚
ä¸å¹¸çš„æ˜¯ï¼Œç”±äºè¿ç»­å•è¯å¯¹â€œdeep learningâ€çš„å‡ºç°é¢‘ç‡è¦ä½å¾—å¤šï¼Œ
æ‰€ä»¥ä¼°è®¡è¿™ç±»å•è¯æ­£ç¡®çš„æ¦‚ç‡è¦å›°éš¾å¾—å¤šã€‚
ç‰¹åˆ«æ˜¯å¯¹äºä¸€äº›ä¸å¸¸è§çš„å•è¯ç»„åˆï¼Œè¦æƒ³æ‰¾åˆ°è¶³å¤Ÿçš„å‡ºç°æ¬¡æ•°æ¥è·å¾—å‡†ç¡®çš„ä¼°è®¡å¯èƒ½éƒ½ä¸å®¹æ˜“ã€‚

ä¸€ç§å¸¸è§çš„ç­–ç•¥æ˜¯æ‰§è¡ŒæŸç§å½¢å¼çš„*æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘*ï¼ˆLaplace smoothingï¼‰ï¼Œ
å…·ä½“æ–¹æ³•æ˜¯åœ¨æ‰€æœ‰è®¡æ•°ä¸­æ·»åŠ ä¸€ä¸ªå°å¸¸é‡ã€‚
ç”¨$n$è¡¨ç¤ºè®­ç»ƒé›†ä¸­çš„å•è¯æ€»æ•°ï¼Œç”¨$m$è¡¨ç¤ºå”¯ä¸€å•è¯çš„æ•°é‡ã€‚
æ­¤è§£å†³æ–¹æ¡ˆæœ‰åŠ©äºå¤„ç†å•å…ƒç´ é—®é¢˜ï¼Œä¾‹å¦‚é€šè¿‡ï¼š

$$
\begin{aligned}
    \hat{P}(x) & = \frac{n(x) + \epsilon_1/m}{n + \epsilon_1}, \\
    \hat{P}(x' \mid x) & = \frac{n(x, x') + \epsilon_2 \hat{P}(x')}{n(x) + \epsilon_2}, \\
    \hat{P}(x'' \mid x,x') & = \frac{n(x, x',x'') + \epsilon_3 \hat{P}(x'')}{n(x, x') + \epsilon_3}.
\end{aligned}
$$

å…¶ä¸­ï¼Œ$\epsilon_1,\epsilon_2$å’Œ$\epsilon_3$æ˜¯è¶…å‚æ•°ã€‚
ä»¥$\epsilon_1$ä¸ºä¾‹ï¼šå½“$\epsilon_1 = 0$æ—¶ï¼Œä¸åº”ç”¨å¹³æ»‘ï¼›
å½“$\epsilon_1$æ¥è¿‘æ­£æ— ç©·å¤§æ—¶ï¼Œ$\hat{P}(x)$æ¥è¿‘å‡åŒ€æ¦‚ç‡åˆ†å¸ƒ$1/m$ã€‚

è¿™æ ·çš„æ¨¡å‹å¾ˆå®¹æ˜“å˜å¾—æ— æ•ˆï¼ŒåŸå› å¦‚ä¸‹ï¼š é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å­˜å‚¨æ‰€æœ‰çš„è®¡æ•°ï¼› å…¶æ¬¡ï¼Œè¿™å®Œå…¨å¿½ç•¥äº†å•è¯çš„æ„æ€ã€‚ ä¾‹å¦‚ï¼Œâ€œçŒ«â€ï¼ˆcatï¼‰å’Œâ€œçŒ«ç§‘åŠ¨ç‰©â€ï¼ˆfelineï¼‰å¯èƒ½å‡ºç°åœ¨ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œ

## é©¬å°”ç§‘å¤«æ¨¡å‹ä¸nå…ƒè¯­æ³•

Â å¦‚æœğ‘ƒ(ğ‘¥ğ‘¡+1âˆ£ğ‘¥ğ‘¡,â€¦,ğ‘¥1)=ğ‘ƒ(ğ‘¥ğ‘¡+1âˆ£ğ‘¥ğ‘¡)ï¼Œ åˆ™åºåˆ—ä¸Šçš„åˆ†å¸ƒæ»¡è¶³ä¸€é˜¶é©¬å°”å¯å¤«æ€§è´¨ã€‚

å¯ä»¥åº”ç”¨äºåºåˆ—å»ºæ¨¡çš„è¿‘ä¼¼å…¬å¼ï¼š

$$
\begin{aligned}
P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2) P(x_3) P(x_4),\\
P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_2) P(x_4  \mid  x_3),\\
P(x_1, x_2, x_3, x_4) &=  P(x_1) P(x_2  \mid  x_1) P(x_3  \mid  x_1, x_2) P(x_4  \mid  x_2, x_3).
\end{aligned}
$$

é€šå¸¸ï¼Œæ¶‰åŠä¸€ä¸ªã€ä¸¤ä¸ªå’Œä¸‰ä¸ªå˜é‡çš„æ¦‚ç‡å…¬å¼åˆ†åˆ«è¢«ç§°ä¸º
*ä¸€å…ƒè¯­æ³•*ï¼ˆunigramï¼‰ã€*äºŒå…ƒè¯­æ³•*ï¼ˆbigramï¼‰å’Œ*ä¸‰å…ƒè¯­æ³•*ï¼ˆtrigramï¼‰æ¨¡å‹ã€‚

## è‡ªç„¶è¯­è¨€ç»Ÿè®¡

![[Pasted image 20251103012703.png]]

å°†å‰å‡ ä¸ªå•è¯ä½œä¸ºä¾‹å¤–æ¶ˆé™¤åï¼Œå‰©ä½™çš„æ‰€æœ‰å•è¯å¤§è‡´éµå¾ªåŒå¯¹æ•°åæ ‡å›¾ä¸Šçš„ä¸€æ¡ç›´çº¿ã€‚
è¿™æ„å‘³ç€å•è¯çš„é¢‘ç‡æ»¡è¶³*é½æ™®å¤«å®šå¾‹*ï¼ˆZipf's lawï¼‰ï¼Œ
å³ç¬¬$i$ä¸ªæœ€å¸¸ç”¨å•è¯çš„é¢‘ç‡$n_i$ä¸ºï¼š

$$n_i \propto \frac{1}{i^\alpha},$$


ç­‰ä»·äº

$$\log n_i = -\alpha \log i + c,$$

å…¶ä¸­$\alpha$æ˜¯åˆ»ç”»åˆ†å¸ƒçš„æŒ‡æ•°ï¼Œ$c$æ˜¯å¸¸æ•°ã€‚

è¿™å‘Šè¯‰æˆ‘ä»¬æƒ³è¦é€šè¿‡è®¡æ•°ç»Ÿè®¡å’Œå¹³æ»‘æ¥å»ºæ¨¡å•è¯æ˜¯ä¸å¯è¡Œçš„ï¼Œ å› ä¸ºè¿™æ ·å»ºæ¨¡çš„ç»“æœä¼šå¤§å¤§é«˜ä¼°å°¾éƒ¨å•è¯çš„é¢‘ç‡ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„ä¸å¸¸ç”¨å•è¯ã€‚ é‚£ä¹ˆ[**å…¶ä»–çš„è¯å…ƒç»„åˆï¼Œæ¯”å¦‚äºŒå…ƒè¯­æ³•ã€ä¸‰å…ƒè¯­æ³•ç­‰ç­‰ï¼Œåˆä¼šå¦‚ä½•å‘¢ï¼Ÿ**]

```python
bigram_tokens = [pair for pair in zip(corpus[:-1], corpus[1:])]
bigram_vocab = d2l.Vocab(bigram_tokens)
bigram_vocab.token_freqs[:10]
```

```python
trigram_tokens = [triple for triple in zip(
    corpus[:-2], corpus[1:-1], corpus[2:])]
trigram_vocab = d2l.Vocab(trigram_tokens)
trigram_vocab.token_freqs[:10]
```

![[Pasted image 20251103013259.png]]

å¾ˆå¤šğ‘›å…ƒç»„å¾ˆå°‘å‡ºç°ï¼Œè¿™ä½¿å¾—æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘éå¸¸ä¸é€‚åˆè¯­è¨€å»ºæ¨¡ã€‚ ä½œä¸ºä»£æ›¿ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åŸºäºæ·±åº¦å­¦ä¹ çš„æ¨¡å‹ã€‚


## è¯»å–é•¿åºåˆ—æ•°æ®

ç°åœ¨çš„é—®é¢˜æ˜¯å¦‚ä½•[**éšæœºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡æ•°æ®çš„ç‰¹å¾å’Œæ ‡ç­¾ä»¥ä¾›è¯»å–ã€‚**]

![[Pasted image 20251104233936.png]]
æˆ‘ä»¬å¯ä»¥ä»éšæœºåç§»é‡å¼€å§‹åˆ’åˆ†åºåˆ—ï¼Œ ä»¥åŒæ—¶è·å¾—_è¦†ç›–æ€§_ï¼ˆcoverageï¼‰å’Œ_éšæœºæ€§_ï¼ˆrandomnessï¼‰ã€‚

### éšæœºé‡‡æ ·


å¯¹äºè¯­è¨€å»ºæ¨¡ï¼Œç›®æ ‡æ˜¯åŸºäºåˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬çœ‹åˆ°çš„è¯å…ƒæ¥é¢„æµ‹ä¸‹ä¸€ä¸ªè¯å…ƒï¼Œ å› æ­¤æ ‡ç­¾æ˜¯ç§»ä½äº†ä¸€ä¸ªè¯å…ƒçš„åŸå§‹åºåˆ—ã€‚

å‚æ•°`batch_size`æŒ‡å®šäº†æ¯ä¸ªå°æ‰¹é‡ä¸­å­åºåˆ—æ ·æœ¬çš„æ•°ç›®ï¼Œ å‚æ•°`num_steps`æ˜¯æ¯ä¸ªå­åºåˆ—ä¸­é¢„å®šä¹‰çš„æ—¶é—´æ­¥æ•°ã€‚

```python
def seq_data_iter_random(corpus, batch_size, num_steps):  #@save
    """ä½¿ç”¨éšæœºæŠ½æ ·ç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡å­åºåˆ—"""
    # ä»éšæœºåç§»é‡å¼€å§‹å¯¹åºåˆ—è¿›è¡Œåˆ†åŒºï¼ŒéšæœºèŒƒå›´åŒ…æ‹¬num_steps-1
    corpus = corpus[random.randint(0, num_steps - 1):]
    # å‡å»1ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬éœ€è¦è€ƒè™‘æ ‡ç­¾
    num_subseqs = (len(corpus) - 1) // num_steps
    # é•¿åº¦ä¸ºnum_stepsçš„å­åºåˆ—çš„èµ·å§‹ç´¢å¼•
    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))
    # åœ¨éšæœºæŠ½æ ·çš„è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œ
    # æ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„ã€éšæœºçš„ã€å°æ‰¹é‡ä¸­çš„å­åºåˆ—ä¸ä¸€å®šåœ¨åŸå§‹åºåˆ—ä¸Šç›¸é‚»
    random.shuffle(initial_indices)

    def data(pos):
        # è¿”å›ä»posä½ç½®å¼€å§‹çš„é•¿åº¦ä¸ºnum_stepsçš„åºåˆ—
        return corpus[pos: pos + num_steps]

    num_batches = num_subseqs // batch_size
    for i in range(0, batch_size * num_batches, batch_size):
        # åœ¨è¿™é‡Œï¼Œinitial_indicesåŒ…å«å­åºåˆ—çš„éšæœºèµ·å§‹ç´¢å¼•
        initial_indices_per_batch = initial_indices[i: i + batch_size]
        X = [data(j) for j in initial_indices_per_batch]
        Y = [data(j + 1) for j in initial_indices_per_batch]
        yield torch.tensor(X), torch.tensor(Y)
```

```python
my_seq = list(range(35))
for X, Y in seq_data_iter_random(my_seq, batch_size=2, num_steps=5):
    print('X: ', X, '\nY:', Y)
```

### é¡ºåºåˆ†åŒº

æˆ‘ä»¬è¿˜å¯ä»¥[**ä¿è¯ä¸¤ä¸ªç›¸é‚»çš„å°æ‰¹é‡ä¸­çš„å­åºåˆ—åœ¨åŸå§‹åºåˆ—ä¸Šä¹Ÿæ˜¯ç›¸é‚»çš„**]ã€‚ è¿™ç§ç­–ç•¥åœ¨åŸºäºå°æ‰¹é‡çš„è¿­ä»£è¿‡ç¨‹ä¸­ä¿ç•™äº†æ‹†åˆ†çš„å­åºåˆ—çš„é¡ºåºï¼Œå› æ­¤ç§°ä¸ºé¡ºåºåˆ†åŒºã€‚

```python
def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save
    """ä½¿ç”¨é¡ºåºåˆ†åŒºç”Ÿæˆä¸€ä¸ªå°æ‰¹é‡å­åºåˆ—"""
    # ä»éšæœºåç§»é‡å¼€å§‹åˆ’åˆ†åºåˆ—
    offset = random.randint(0, num_steps)
    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size
    Xs = torch.tensor(corpus[offset: offset + num_tokens])
    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])
    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)
    num_batches = Xs.shape[1] // num_steps
    for i in range(0, num_steps * num_batches, num_steps):
        X = Xs[:, i: i + num_steps]
        Y = Ys[:, i: i + num_steps]
        yield X, Y
```
> **æŠŠ corpus é¡ºåºåˆ‡æˆ batch_size è¡Œçš„çŸ©é˜µï¼Œæ¯æ¬¡ä»ä¸­æŒ‰åˆ—åˆ‡ num_steps ä¸ªæ—¶é—´æ­¥ï¼Œä½œä¸ºä¸€ä¸ª batch é€å‡ºè®­ç»ƒã€‚**

æˆ‘ä»¬[**å°†ä¸Šé¢çš„ä¸¤ä¸ªé‡‡æ ·å‡½æ•°åŒ…è£…åˆ°ä¸€ä¸ªç±»ä¸­**]ï¼Œ ä»¥ä¾¿ç¨åå¯ä»¥å°†å…¶ç”¨ä½œæ•°æ®è¿­ä»£å™¨

```python
class SeqDataLoader:  #@save
    """åŠ è½½åºåˆ—æ•°æ®çš„è¿­ä»£å™¨"""
    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):
        if use_random_iter:
            self.data_iter_fn = d2l.seq_data_iter_random
        else:
            self.data_iter_fn = d2l.seq_data_iter_sequential
        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)
        self.batch_size, self.num_steps = batch_size, num_steps

    def __iter__(self):
        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)
```

 iter æ–¹æ³•
 è®©è¿™ä¸ªç±»çš„å¯¹è±¡å¯ä»¥è¢«è¿™æ ·ä½¿ç”¨ï¼š
 for X, Y in SeqDataLoader(...):
    ...

**æœ€åï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå‡½æ•°`load_data_time_machine`ï¼Œ å®ƒåŒæ—¶è¿”å›æ•°æ®è¿­ä»£å™¨å’Œè¯è¡¨**

```python
def load_data_time_machine(batch_size, num_steps,  #@save
                           use_random_iter=False, max_tokens=10000):
    """è¿”å›æ—¶å…‰æœºå™¨æ•°æ®é›†çš„è¿­ä»£å™¨å’Œè¯è¡¨"""
    data_iter = SeqDataLoader(
        batch_size, num_steps, use_random_iter, max_tokens)
    return data_iter, data_iter.vocab
```

## å°ç»“

- è¯­è¨€æ¨¡å‹æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„å…³é”®ã€‚
- ğ‘›å…ƒè¯­æ³•é€šè¿‡æˆªæ–­ç›¸å…³æ€§ï¼Œä¸ºå¤„ç†é•¿åºåˆ—æä¾›äº†ä¸€ç§å®ç”¨çš„æ¨¡å‹ã€‚
- é•¿åºåˆ—å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼šå®ƒä»¬å¾ˆå°‘å‡ºç°æˆ–è€…ä»ä¸å‡ºç°ã€‚
- é½æ™®å¤«å®šå¾‹æ”¯é…ç€å•è¯çš„åˆ†å¸ƒï¼Œè¿™ä¸ªåˆ†å¸ƒä¸ä»…é€‚ç”¨äºä¸€å…ƒè¯­æ³•ï¼Œè¿˜é€‚ç”¨äºå…¶ä»–ğ‘›å…ƒè¯­æ³•ã€‚
- é€šè¿‡æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘æ³•å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ç»“æ„ä¸°å¯Œè€Œé¢‘ç‡ä¸è¶³çš„ä½é¢‘è¯è¯ç»„ã€‚
- è¯»å–é•¿åºåˆ—çš„ä¸»è¦æ–¹å¼æ˜¯éšæœºé‡‡æ ·å’Œé¡ºåºåˆ†åŒºã€‚åœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œåè€…å¯ä»¥ä¿è¯æ¥è‡ªä¸¤ä¸ªç›¸é‚»çš„å°æ‰¹é‡ä¸­çš„å­åºåˆ—åœ¨åŸå§‹åºåˆ—ä¸Šä¹Ÿæ˜¯ç›¸é‚»çš„ã€‚

