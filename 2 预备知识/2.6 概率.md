## 1 基本概率论

_大数定律_（law of large numbers）告诉我们： 随着投掷次数的增加，这个估计值会越来越接近真实的潜在概率。

在统计学中，我们把从概率分布中抽取样本的过程称为_抽样_（sampling）

如果用Python的for循环来完成这个任务，速度会慢得惊人。 因此我们使用深度学习框架的函数同时抽取多个样本，得到我们想要的任意形状的独立样本数组。

fair_probs = torch.ones([6]) / 6

multinomial.Multinomial(10, fair_probs).sample()

tensor([5., 3., 2., 0., 0., 0.])

### 概率论公理

将集合S称为_样本空间_（sample space）或_结果空间_（outcome space）， 其中每个元素都是_结果_（outcome）
 
 _事件_（event）是一组给定样本空间的随机结果。

![[Pasted image 20251026163032.png]]

### 随机变量

_离散_（discrete）随机变量（如骰子的每一面） 和_连续_（continuous）随机变量（如人的体重和身高）之间存在微妙的区别

我们将这个看到某个数值的可能性量化为_密度_（density）

## 2 处理多个随机变量

1. 联合概率
2. 条件概率
3. 贝叶斯定理
![[Pasted image 20251026163418.png]]
4. 边际化
![[Pasted image 20251026163529.png]]

边际化结果的概率或分布称为_边际概率_（marginal probability） 或_边际分布_（marginal distribution）。

5. 独立性
条件独立
6. 应用
艾滋病阳性检测 两次检测正确率

## 3 期望和方差

 随机变量函数的方差衡量的是：当从该随机变量分布中采样不同值时， 函数值偏离该函数的期望的程度。
![[Pasted image 20251026164029.png]]

## 4 小结

- 我们可以从概率分布中采样。
    
- 我们可以使用联合分布、条件分布、Bayes定理、边缘化和独立性假设来分析多个随机变量。
    
- 期望和方差为概率分布的关键特征的概括提供了实用的度量形式。

## 5 练习

![[Pasted image 20251026164133.png]]

1.
```python
import torch
from torch.distributions import multinomial

fair_probs = torch.ones(6) / 6  # 骰子均匀分布
m, n = 500, 10

counts = multinomial.Multinomial(n, fair_probs).sample((m,))
cum_counts = counts.cumsum(dim=0)
estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)
```

 2.
 并集概率不会超过两事件概率之和，交集概率不会超过较小者。

3.
$$

P(A,B,C) = P(A) P(B|A) P(C|B)

$$
4.
因为**两个测试相互独立、结果分布相同**，重复运行并不会提供新信息；
同时运行两个实验能更快地收集样本、减少方差。
解释：
在蒙特卡洛实验中，同时并行执行多个独立实验，比重复单一实验更高效，且结果统计意义相同。