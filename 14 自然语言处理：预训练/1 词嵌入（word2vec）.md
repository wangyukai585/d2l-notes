_自然语言处理_是指研究使用自然语言的计算机和人类之间的交互。

 _自监督学习_（self-supervised learning） 已被广泛用于预训练文本表示， 例如通过使用周围文本的其它部分来预测文本的隐藏部分。 通过这种方式，模型可以通过有监督地从_海量_文本数据中学习，而不需要_昂贵_的标签标注！

当将每个单词或子词视为单个词元时， 可以在大型语料库上使用word2vec、GloVe或子词嵌入模型预先训练每个词元的词元。 经过预训练后，每个词元的表示可以是一个向量。 但是，无论上下文是什么，它都保持不变。

![[Pasted image 20251118225152.png]]

--- 
 _词向量_是用于表示单词意义的向量， 并且还可以被认为是单词的特征向量或表示。 将单词映射到实向量的技术称为_词嵌入_。

独热向量不能准确表达不同词之间的相似度。

## 自监督的word2vec

它将每个词映射到一个固定长度的向量，这些向量能更好地表达不同词之间的相似性和类比关系。word2vec工具包含两个模型，即_跳元模型_（skip-gram） :cite:`Mikolov.Sutskever.Chen.ea.2013`和_连续词袋_（CBOW） :cite:`Mikolov.Chen.Corrado.ea.2013`

### 跳元模型

